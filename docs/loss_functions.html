---

title: loss_functions

keywords: fastai
sidebar: home_sidebar

summary: "This module contains implementations of both <a href='https://arxiv.org/pdf/1809.02403.pdf'>traditional survival analysis functions](https://square.github.io/pysurvival/math.html), as well as the loss functions associated with uncensored data, as defined in the [original DRSA paper</a>."
description: "This module contains implementations of both <a href='https://arxiv.org/pdf/1809.02403.pdf'>traditional survival analysis functions](https://square.github.io/pysurvival/math.html), as well as the loss functions associated with uncensored data, as defined in the [original DRSA paper</a>."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebooks/00_loss_functions.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Survival-Analysis-Functions">Survival Analysis Functions<a class="anchor-link" href="#Survival-Analysis-Functions"> </a></h2><p>Following the notation used in the the <a href="https://arxiv.org/pdf/1809.02403.pdf">DRSA paper</a>, we define the following:</p>
<ul>
<li><p>Let $z$ be the true occurrence time for the event of interest.</p>
</li>
<li><p>Let $t$ be the time that a given data point was observed.</p>
</li>
<li><p>For each observation, there exist $L$ time slices, ie $0 &lt; t_1 &lt; t_2 &lt; \dots &lt; t_L$, at which we either observe the event (uncensored) or do not (censored).</p>
</li>
<li><p>Let $V_l = (t_{l-1}, t_l]$ be the set of all disjoint intervals with $l = 1, 2, \dots, L$.</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Discrete-Survival-function">Discrete Survival function<a class="anchor-link" href="#Discrete-Survival-function"> </a></h3><p>Though it's given its own name is survival analysis, the survival function is simply calculated as $1 - \text{CDF}(z)$. In the discrete, empirical case, the survival function is estimated as follows (this is equation (5) in the paper).</p>
<p>{% raw %}
$$ S(t_l) = Pr(z &gt; t_l) = \sum_{j &gt; l}Pr(z\in V_j) $$
{% endraw %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="survival_rate" class="doc_header"><code>survival_rate</code><a href="https://github.com/collinprather/drsa/tree/master/drsa/loss_functions.py#L10" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>survival_rate</code>(<strong><code>h</code></strong>)</p>
</blockquote>
<p>Given the predicted conditional hazard rate, this function estimates
the survival rate.</p>
<p><em>input</em>:</p>
<ul>
<li><code>h</code>:<ul>
<li>type: <code>torch.tensor</code>,</li>
<li>predicted conditional hazard rate, at each observed time step.</li>
<li>note: <code>h.shape == (batch size, 1, 1)</code>, as this is most amenable to use in training neural nets with pytorch.</li>
</ul>
</li>
</ul>
<p><em>output</em>:</p>
<ul>
<li><code>s</code>:<ul>
<li>type: <code>torch.tensor</code></li>
<li>estimated survival rate at time t.</li>
<li>note: <code>s.shape == (batch_size, 1)</code></li>
</ul>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># example</span>
<span class="n">h1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.001</span><span class="p">],</span>
                   <span class="p">[</span><span class="mf">0.5</span><span class="p">],</span>
                   <span class="p">[</span><span class="mf">0.55</span><span class="p">],</span>
                   <span class="p">[</span><span class="mf">0.15</span><span class="p">],</span>
                   <span class="p">[</span><span class="mf">0.15</span><span class="p">],</span>
                   <span class="p">[</span><span class="mf">0.15</span><span class="p">],</span>
                   <span class="p">[</span><span class="mf">0.15</span><span class="p">],</span>
                   <span class="p">[</span><span class="mf">0.9</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">h2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.001</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.005</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.1</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.11</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.12</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.15</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.15</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.9</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">h1</span><span class="p">,</span> <span class="n">h2</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">survival_rate</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[0.0117],
        [0.0506]], grad_fn=&lt;ProdBackward1&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Discrete-Event-Rate-function">Discrete Event Rate function<a class="anchor-link" href="#Discrete-Event-Rate-function"> </a></h3><p>The event rate function is calculated as $\text{CDF}(z)$. In the discrete, empirical case, it is estimated as follows (this is equation (5) in the paper).</p>
<p>{% raw %}
$$ W(t_l) = Pr(z \leq t_l) = \sum_{j\leq l}Pr(z\in V_j) $$
{% endraw %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="event_rate" class="doc_header"><code>event_rate</code><a href="https://github.com/collinprather/drsa/tree/master/drsa/loss_functions.py#L34" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>event_rate</code>(<strong><code>h</code></strong>)</p>
</blockquote>
<p>Given the predicted conditional hazard rate, this function estimates
the event rate.</p>
<p><em>input</em>:</p>
<ul>
<li><code>h</code>:<ul>
<li>type: <code>torch.tensor</code>,</li>
<li>predicted conditional hazard rate, at each observed time step.</li>
<li>note: <code>h.shape == (batch size, 1, 1)</code>, as this is most amenable to use in training neural nets with pytorch.</li>
</ul>
</li>
</ul>
<p><em>output</em>:</p>
<ul>
<li><code>w</code>:<ul>
<li>type: <code>torch.tensor</code></li>
<li>estimated survival rate at time t.</li>
<li>note: <code>s.shape == (batch_size, 1)</code></li>
</ul>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># example</span>
<span class="n">event_rate</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[0.9883],
        [0.9494]], grad_fn=&lt;RsubBackward1&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Discrete-Event-Time-Probability-function">Discrete Event Time Probability function<a class="anchor-link" href="#Discrete-Event-Time-Probability-function"> </a></h3><p>The event time probability function is calculated as $\text{PDF}(z)$. In the discrete, empirical case, it is estimated as follows (this is equation (6) in the paper).</p>
<p>{% raw %}
$$p_l = Pr(z\in V_t) = W(t_l) - W(t_{l-1}) = S(t_{l-1}) - S(t_{l})$$
{% endraw %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="event_time" class="doc_header"><code>event_time</code><a href="https://github.com/collinprather/drsa/tree/master/drsa/loss_functions.py#L58" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>event_time</code>(<strong><code>h</code></strong>)</p>
</blockquote>
<p>Given the predicted conditional hazard rate, this function estimates
the probability that the event occurs at time t.</p>
<p><em>input</em>:</p>
<ul>
<li><code>h</code>:<ul>
<li>type: <code>torch.tensor</code>,</li>
<li>predicted conditional hazard rate, at each observed time step.</li>
<li>note: <code>h.shape == (batch size, 1, 1)</code>, as this is most amenable to use in training neural nets with pytorch.</li>
</ul>
</li>
</ul>
<p><em>output</em>:</p>
<ul>
<li><code>p</code>:<ul>
<li>type: <code>torch.tensor</code></li>
<li>estimated probability of event at time t.</li>
<li>note: <code>s.shape == (batch_size, 1)</code></li>
</ul>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># example</span>
<span class="n">event_time</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[0.1056],
        [0.4556]], grad_fn=&lt;MulBackward0&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Discrete-Conditional-Hazard-Rate">Discrete Conditional Hazard Rate<a class="anchor-link" href="#Discrete-Conditional-Hazard-Rate"> </a></h3><p>The conditional hazard rate is the quantity which will be predicted at each time step by a recurrent survival analysis model. In the discrete, empirical case, it is estimated as follows (this is equation (7) in the paper).</p>
<p>{% raw %}
$$h_l = Pr(z\in V_l | z &gt; t_{l-1}) = \frac{Pr(z\in V_l)}{Pr(z&gt;t_{l-1})} = \frac{p_l}{S(t_{l-1})}$$
{% endraw %}</p>

</div>
</div>
</div>
</div>
 

