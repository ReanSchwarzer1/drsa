---

title: Functions

keywords: fastai
sidebar: home_sidebar

summary: "This module contains implementations of both <a href='https://arxiv.org/pdf/1809.02403.pdf'>traditional survival analysis functions](https://square.github.io/pysurvival/math.html), as well as the loss functions associated with uncensored data, as defined in the [original DRSA paper</a>."
description: "This module contains implementations of both <a href='https://arxiv.org/pdf/1809.02403.pdf'>traditional survival analysis functions](https://square.github.io/pysurvival/math.html), as well as the loss functions associated with uncensored data, as defined in the [original DRSA paper</a>."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebooks/00_functions.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Survival-Analysis-Functions">Survival Analysis Functions<a class="anchor-link" href="#Survival-Analysis-Functions"> </a></h2><p>Following the notation used in the the <a href="https://arxiv.org/pdf/1809.02403.pdf">DRSA paper</a>, we define the following:</p>
<ul>
<li><p>Let $z$ be the true occurrence time for the event of interest.</p>
</li>
<li><p>Let $t$ be the time that a given data point was observed.</p>
</li>
<li><p>For each observation, there exist $L$ time slices, ie $0 &lt; t_1 &lt; t_2 &lt; \dots &lt; t_L$, at which we either observe the event (uncensored) or do not (censored).</p>
</li>
<li><p>Let $V_l = (t_{l-1}, t_l]$ be the set of all disjoint intervals with $l = 1, 2, \dots, L$.</p>
</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="assert_correct_input_shape" class="doc_header"><code>assert_correct_input_shape</code><a href="https://github.com/collinprather/drsa/tree/master/drsa/functions.py#L12" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>assert_correct_input_shape</code>(<strong><code>h</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="assert_correct_output_shape" class="doc_header"><code>assert_correct_output_shape</code><a href="https://github.com/collinprather/drsa/tree/master/drsa/functions.py#L16" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>assert_correct_output_shape</code>(<strong><code>q</code></strong>, <strong><code>batch_size</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Discrete-Survival-function">Discrete Survival function<a class="anchor-link" href="#Discrete-Survival-function"> </a></h3><p>Though it's given its own name is survival analysis, the survival function is simply calculated as $1 - \text{CDF}(z)$. In the discrete, empirical case, the survival function is estimated as follows (this is equation (5) in the paper).</p>
<p>{% raw %}
$$ S(t_l) = Pr(z &gt; t_l) = \sum_{j &gt; l}Pr(z\in V_j) $$
{% endraw %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="survival_rate" class="doc_header"><code>survival_rate</code><a href="https://github.com/collinprather/drsa/tree/master/drsa/functions.py#L22" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>survival_rate</code>(<strong><code>h</code></strong>)</p>
</blockquote>
<p>Given the predicted conditional hazard rate, this function estimates
the survival rate.</p>
<p><em>input</em>:</p>
<ul>
<li><code>h</code>:<ul>
<li>type: <code>torch.tensor</code>,</li>
<li>predicted conditional hazard rate, at each observed time step.</li>
<li>note: <code>h.shape == (batch size, 1, 1)</code>, as this is most amenable to use in training neural nets with pytorch.</li>
</ul>
</li>
</ul>
<p><em>output</em>:</p>
<ul>
<li><code>s</code>:<ul>
<li>type: <code>torch.tensor</code></li>
<li>estimated survival rate at time t.</li>
<li>note: <code>s.shape == (batch_size, 1)</code></li>
</ul>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># example</span>
<span class="n">h1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.001</span><span class="p">],</span>
                   <span class="p">[</span><span class="mf">0.5</span><span class="p">],</span>
                   <span class="p">[</span><span class="mf">0.55</span><span class="p">],</span>
                   <span class="p">[</span><span class="mf">0.15</span><span class="p">],</span>
                   <span class="p">[</span><span class="mf">0.15</span><span class="p">],</span>
                   <span class="p">[</span><span class="mf">0.15</span><span class="p">],</span>
                   <span class="p">[</span><span class="mf">0.15</span><span class="p">],</span>
                   <span class="p">[</span><span class="mf">0.9</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">h2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.001</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.005</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.1</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.11</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.12</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.15</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.15</span><span class="p">],</span>
                    <span class="p">[</span><span class="mf">0.9</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">h1</span><span class="p">,</span> <span class="n">h2</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">survival_rate</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[0.0117],
        [0.0506]], grad_fn=&lt;ProdBackward1&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Discrete-Event-Rate-function">Discrete Event Rate function<a class="anchor-link" href="#Discrete-Event-Rate-function"> </a></h3><p>The event rate function is calculated as $\text{CDF}(z)$. In the discrete, empirical case, it is estimated as follows (this is equation (5) in the paper).</p>
<p>{% raw %}
$$ W(t_l) = Pr(z \leq t_l) = \sum_{j\leq l}Pr(z\in V_j) $$
{% endraw %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="event_rate" class="doc_header"><code>event_rate</code><a href="https://github.com/collinprather/drsa/tree/master/drsa/functions.py#L45" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>event_rate</code>(<strong><code>h</code></strong>)</p>
</blockquote>
<p>Given the predicted conditional hazard rate, this function estimates
the event rate.</p>
<p><em>input</em>:</p>
<ul>
<li><code>h</code>:<ul>
<li>type: <code>torch.tensor</code>,</li>
<li>predicted conditional hazard rate, at each observed time step.</li>
<li>note: <code>h.shape == (batch size, 1, 1)</code>, as this is most amenable to use in training neural nets with pytorch.</li>
</ul>
</li>
</ul>
<p><em>output</em>:</p>
<ul>
<li><code>w</code>:<ul>
<li>type: <code>torch.tensor</code></li>
<li>estimated survival rate at time t.</li>
<li>note: <code>w.shape == (batch_size, 1)</code></li>
</ul>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># example</span>
<span class="n">event_rate</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[0.9883],
        [0.9494]], grad_fn=&lt;RsubBackward1&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Discrete-Event-Time-Probability-function">Discrete Event Time Probability function<a class="anchor-link" href="#Discrete-Event-Time-Probability-function"> </a></h3><p>The event time probability function is calculated as $\text{PDF}(z)$. In the discrete, empirical case, it is estimated as follows (this is equation (6) in the paper).</p>
<p>{% raw %}
$$p_l = Pr(z\in V_t) = W(t_l) - W(t_{l-1}) = S(t_{l-1}) - S(t_{l})$$
{% endraw %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="event_time" class="doc_header"><code>event_time</code><a href="https://github.com/collinprather/drsa/tree/master/drsa/functions.py#L68" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>event_time</code>(<strong><code>h</code></strong>)</p>
</blockquote>
<p>Given the predicted conditional hazard rate, this function estimates
the probability that the event occurs at time t.</p>
<p><em>input</em>:</p>
<ul>
<li><code>h</code>:<ul>
<li>type: <code>torch.tensor</code>,</li>
<li>predicted conditional hazard rate, at each observed time step.</li>
<li>note: <code>h.shape == (batch size, 1, 1)</code>, as this is most amenable to use in training neural nets with pytorch.</li>
</ul>
</li>
</ul>
<p><em>output</em>:</p>
<ul>
<li><code>p</code>:<ul>
<li>type: <code>torch.tensor</code></li>
<li>estimated probability of event at time t.</li>
<li>note: <code>p.shape == (batch_size, 1)</code></li>
</ul>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># example</span>
<span class="n">event_time</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[0.1056],
        [0.4556]], grad_fn=&lt;MulBackward0&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Discrete-Conditional-Hazard-Rate">Discrete Conditional Hazard Rate<a class="anchor-link" href="#Discrete-Conditional-Hazard-Rate"> </a></h3><p>The conditional hazard rate is the quantity which will be predicted at each time step by a recurrent survival analysis model. In the discrete, empirical case, it is estimated as follows (this is equation (7) in the paper).</p>
<p>{% raw %}
$$h_l = Pr(z\in V_l | z &gt; t_{l-1}) = \frac{Pr(z\in V_l)}{Pr(z&gt;t_{l-1})} = \frac{p_l}{S(t_{l-1})}$$
{% endraw %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Log-Survival-Analysis-Functions">Log Survival Analysis Functions<a class="anchor-link" href="#Log-Survival-Analysis-Functions"> </a></h2><p>We additionally define the log of each of the traditional survival analysis functions, which prove useful for computational stability, being that we need to multiply many float point decimal values together.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Log-Survival-Function">Log Survival Function<a class="anchor-link" href="#Log-Survival-Function"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="log_survival_rate" class="doc_header"><code>log_survival_rate</code><a href="https://github.com/collinprather/drsa/tree/master/drsa/functions.py#L91" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>log_survival_rate</code>(<strong><code>h</code></strong>)</p>
</blockquote>
<p>Given the predicted conditional hazard rate, this function estimates
the log survival rate.</p>
<p><em>input</em>:</p>
<ul>
<li><code>h</code>:<ul>
<li>type: <code>torch.tensor</code>,</li>
<li>predicted conditional hazard rate, at each observed time step.</li>
<li>note: <code>h.shape == (batch size, 1, 1)</code>, as this is most amenable to use in training neural nets with pytorch.</li>
</ul>
</li>
</ul>
<p><em>output</em>:</p>
<ul>
<li><code>s</code>:<ul>
<li>type: <code>torch.tensor</code></li>
<li>estimated log survival rate at time t.</li>
<li>note: <code>s.shape == (batch_size, 1)</code></li>
</ul>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#example</span>
<span class="n">log_survival_rate</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[-4.4453],
        [-2.9834]], grad_fn=&lt;SumBackward1&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Log-Event-Rate-Function">Log Event Rate Function<a class="anchor-link" href="#Log-Event-Rate-Function"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="log_event_rate" class="doc_header"><code>log_event_rate</code><a href="https://github.com/collinprather/drsa/tree/master/drsa/functions.py#L114" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>log_event_rate</code>(<strong><code>h</code></strong>)</p>
</blockquote>
<p>Given the predicted conditional hazard rate, this function estimates
the log event rate.</p>
<p><em>input</em>:</p>
<ul>
<li><code>h</code>:<ul>
<li>type: <code>torch.tensor</code>,</li>
<li>predicted conditional hazard rate, at each observed time step.</li>
<li>note: <code>h.shape == (batch size, 1, 1)</code>, as this is most amenable to use in training neural nets with pytorch.</li>
</ul>
</li>
</ul>
<p><em>output</em>:</p>
<ul>
<li><code>w</code>:<ul>
<li>type: <code>torch.tensor</code></li>
<li>estimated log survival rate at time t.</li>
<li>note: <code>w.shape == (batch_size, 1)</code></li>
</ul>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># example</span>
<span class="n">log_event_rate</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[-0.0118],
        [-0.0519]], grad_fn=&lt;LogBackward&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Log-Event-Time-Function">Log Event Time Function<a class="anchor-link" href="#Log-Event-Time-Function"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="log_event_time" class="doc_header"><code>log_event_time</code><a href="https://github.com/collinprather/drsa/tree/master/drsa/functions.py#L137" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>log_event_time</code>(<strong><code>h</code></strong>)</p>
</blockquote>
<p>Given the predicted conditional hazard rate, this function estimates
the log probability that the event occurs at time t.</p>
<p><em>input</em>:</p>
<ul>
<li><code>h</code>:<ul>
<li>type: <code>torch.tensor</code>,</li>
<li>predicted conditional hazard rate, at each observed time step.</li>
<li>note: <code>h.shape == (batch size, 1, 1)</code>, as this is most amenable to use in training neural nets with pytorch.</li>
</ul>
</li>
</ul>
<p><em>output</em>:</p>
<ul>
<li><code>p</code>:<ul>
<li>type: <code>torch.tensor</code></li>
<li>estimated log probability of event at time t.</li>
<li>note: <code>p.shape == (batch_size, 1)</code></li>
</ul>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># example</span>
<span class="n">log_event_time</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[-2.2481],
        [-0.7861]], grad_fn=&lt;AddBackward0&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loss-Functions">Loss Functions<a class="anchor-link" href="#Loss-Functions"> </a></h2><p>Now, we define the transform these generic survival analysis functions into loss functions that can be automatically differentiated by PyTorch, in order to train a Deep Recurrent Survival Analysis model.</p>
<p>We make a few notes below:</p>
<ol>
<li><p>The functions below adhere to the common pattern used across all of <a href="https://pytorch.org/docs/stable/nn.functional.html#loss-functions"><code>PyTorch</code>'s loss functions</a>, which is to take two arguments named <code>input</code> and <code>target</code>. We note, however, that due to the nature of this survival data, the target is inherent to the data structure and thus unnecessary.</p>
</li>
<li><p>The original DRSA paper defines 3 loss functions, 2 of which are directed towards uncensored data, and 1 of which applies to censored data. This library's focus is on DRSA models using only uncensored data, so those are the only lossed we'll be defining.</p>
</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Event-Time-Loss">Event Time Loss<a class="anchor-link" href="#Event-Time-Loss"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="event_time_loss" class="doc_header"><code>event_time_loss</code><a href="https://github.com/collinprather/drsa/tree/master/drsa/functions.py#L160" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>event_time_loss</code>(<strong><code>input</code></strong>, <strong><code>target</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Loss function applied to uncensored data in order
to optimize the PDF of the true event time, z</p>
<p>input:</p>
<ul>
<li><code>input</code>:<ul>
<li>type: <code>torch.tensor</code>,</li>
<li>predicted conditional hazard rate, at each observed time step.</li>
<li>note: <code>h.shape == (batch size, 1, 1)</code></li>
</ul>
</li>
<li><code>target</code>:<ul>
<li>unused, only present to mimic pytorch loss functions</li>
</ul>
</li>
</ul>
<p>output:</p>
<ul>
<li><code>evt_loss</code>:<ul>
<li>type: <code>torch.tensor</code></li>
<li>Loss associated with how wrong each predicted probability was at each time step</li>
</ul>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># example</span>
<span class="n">event_time_loss</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(3.0342, grad_fn=&lt;NegBackward&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Event-Rate-Loss">Event Rate Loss<a class="anchor-link" href="#Event-Rate-Loss"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="event_rate_loss" class="doc_header"><code>event_rate_loss</code><a href="https://github.com/collinprather/drsa/tree/master/drsa/functions.py#L184" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>event_rate_loss</code>(<strong><code>input</code></strong>, <strong><code>target</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Loss function applied to uncensored data in order
to optimize the CDF of the true event time, z</p>
<p>input:</p>
<ul>
<li><code>input</code>:<ul>
<li>type: <code>torch.tensor</code>,</li>
<li>predicted conditional hazard rate, at each observed time step.</li>
<li>note: <code>h.shape == (batch size, 1, 1)</code></li>
</ul>
</li>
<li><code>target</code>:<ul>
<li>unused, only present to mimic pytorch loss functions</li>
</ul>
</li>
</ul>
<p>output:</p>
<ul>
<li><code>evr_loss</code>:<ul>
<li>type: <code>torch.tensor</code></li>
<li>Loss associated with how cumulative predicted probabilities differ from the ground truth labels.</li>
</ul>
</li>
</ul>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># example</span>
<span class="n">event_rate_loss</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(0.0638, grad_fn=&lt;NegBackward&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

